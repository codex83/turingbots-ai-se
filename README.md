
# Will TuringBots Replace Human Software Developers?
*A Big Data Analysis of Trends in Open Source Coding, Automation, and AI*

**By Hritik Jhaveri | Big Data and Cloud Computing**

---

## ğŸ—‚ï¸ Overview

This project investigates whether AI-powered development toolsâ€”so-called â€œTuringBotsâ€â€”are poised to replace human software developers. By mining trends from the GitHub Archive (over 1.36 TiB of commits and repository data), we analyze shifts in programming language usage, license adoption, automation, and the real impact of AI tools on the software development landscape.

---

## ğŸš€ Main Results & Visualizations

The analysis of over 1.36 TiB of GitHub data reveals several key trends shaping the software development industry.

#### 1. Programming Language Trends
JavaScript remains the most popular language by repository count, highlighting the dominance of web technologies. However, by volume of code, C is the largest, indicating its foundational role in large-scale systems. Python has firmly established itself as the leader in the AI/ML space.

<p align="center">
  <img src="visualizations/top_lang_repo.png" width="400" alt="Top Languages by Repo Count">
  <img src="visualizations/top_lang_bytes.png" width="400" alt="Top Languages by Byte Count">
</p>
<p align="center">
  <img src="visualizations/trend_top_lang_commits.png" width="600" alt="Language Trends Over Time">
</p>

#### 2. The Rise of AI and Data Science
The growth of AI and Data Science is explosive. "AI" is the most frequently mentioned technology keyword in commit messages, and Python's ecosystem of libraries (`numpy`, `tensorflow`, `pandas`) dominates this trend.

<p align="center">
  <img src="visualizations/top_ds_ai.png" width="400" alt="Top DS/AI Keywords">
  <img src="visualizations/top_ds_ai_trend.png" width="400" alt="DS/AI Keyword Trends">
</p>

#### 3. Automation and Developer Workflows
Commit patterns reveal a standard Monday-Friday work week, with activity peaking mid-week. Automation is a significant factor, with bots and CI/CD systems ranking among the top committers. This, along with the high frequency of templated commit messages, points to the increasing role of automation in the development lifecycle.

<p align="center">
  <img src="visualizations/EDA_commits_by_dow.png" width="400" alt="Commits by Day of Week">
  <img src="visualizations/freq_commit_reason.png" width="400" alt="Commit Message Keywords">
</p>

---

## ğŸ’¡ Conclusion

**TuringBots and AI tools will *augment*, not replace, human developers.** They excel at automating repetitive tasks, but humans remain indispensable for creative problem-solving, architectural design, and innovation. The future of software engineering is a collaborative one, where AI handles the rote work, and humans lead on complex and strategic decisions.

---

## ğŸ—ƒï¸ Project Structure

The repository is organized to separate the data analysis notebooks from the visual outputs.

```
.
â”œâ”€â”€ notebooks/              # Jupyter notebooks for data analysis.
â”‚   â”œâ”€â”€ 1_Languages.ipynb
â”‚   â”œâ”€â”€ 2_Commits.ipynb
â”‚   â””â”€â”€ ...
â”œâ”€â”€ visualizations/         # Plots and charts generated by the notebooks.
â”‚   â”œâ”€â”€ top_lang_repo.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸƒâ€â™‚ï¸ How to Run the Analysis

To reproduce the analysis in this project, please follow these steps:

#### 1. Clone the Repository
```bash
git clone https://github.com/codex83/turingbots-ai-se.git
cd turingbots-ai-se
```

#### 2. Set Up the Environment
It is recommended to use a virtual environment.
```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

#### 3. Data Access
This project runs on a 1.36 TiB dataset from the GitHub Archive, which is stored on Google Cloud Storage (GCS). The path to this dataset is hardcoded in the notebooks (`gs://msca-bdp-data-open/final_project_git`).

To run the notebooks, you will need:
-   An environment with access to Google Cloud Storage.
-   An Apache Spark cluster (like Google Cloud Dataproc) to handle the large-scale data processing.

#### 4. Execute the Notebooks
The analysis is split across several Jupyter notebooks in the `notebooks/` directory. It is recommended to run them in numerical order, as they follow the logical flow of the analysis:
1.  `1_Languages.ipynb`: Analyzes language popularity and trends.
2.  `2_Commits.ipynb`: Analyzes commit patterns, seasonality, and keyword trends.
3.  ... and so on.

---

## ğŸ› ï¸ Technologies Used
-   **Data Processing:** Apache Spark
-   **Data Analysis:** Python, Pandas, NumPy
-   **Visualization:** Matplotlib, Seaborn
-   **Platform:** Google Cloud Platform (GCP), Dataproc

